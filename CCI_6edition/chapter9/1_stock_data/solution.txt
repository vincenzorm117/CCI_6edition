QUESTION: Imagine you are building some sort of service that will be called by up to 1,000 client applications to get simlpe end-of-day stock price information (open, close, high, low). You may assume that you already have the data, and you can store it in any format you wish. How would you design the client-facing service that provides the information to client applications? You are responsible for the development, rollout, and ongoing mointoring and maintenance of the feed. Describe the different methods you considered and why you would recommend your approach. Your service can use any technologies you wish, and can distribute the information to the client applications in any mechanism you choose.

This is an interesting question because there are several ways to do this. First lets consider the most basic way to do this: you or someone working with you could print a list of stock data and mail it to your users periodically or on demand. This is not very practical because one you need someone to print the information about 1000 times and they need to mail or deliver it. This comes at a higher labor and material cost as oppose to just simply providing the information by lets say email which is the same just electronically. Now the costs go away. The only cost comes from maintaining the list of people that are on the email list and emailing the list periodically.

Another way might be to upload the file to an ftp server, a Google Drive folder, a Dropbox folder, or something similar. The only cost is uploading the file. There are about 4000 publicly traded companies in the US and there are 4 pieces of price information so the uploaded file for end-of-day stock price information should be less than 1MB in size. Uploading this file or even emailing it should not be a problem. So the costs here are not very big either apart from just having to remember to upload it. 

A more interesting way would be to setup a database that users can access and retrieve the data. Here this gives users more flexibility in their requests. Right now were assuming that users get the latest end-of-day data, so lets assume that the database information is less than a day old. In this case we wouldn't have to worry about storage unless the number of publicly traded companies increases dramatically which it probably won't within our lifetime unless there is a big change of some sort. If we kept all of the end-of-day data for all companies in all time then we would have to worry about storage. One way we can deal with this is by separating the companies into different servers or separating the stock data by date ranges.

The more common approach to this is to have an RSS feed with the data. The feed can be separated into an all page, an individual company page, or all companies per date. Something like this would have to be generated either by a person or a program. If its a person, it would only have to happen every day after all the data is gathered, even then the data can be assimilated by a script the user runs.

The final approach to this is similar to the database, but you would connect it to a server with a REST or GraphQL API that serves this data. With a setup like this, you can add things like caching to speed up throughput and latency. At the same time, having the server layer can add another layer of security because your database is not exposed to the world.